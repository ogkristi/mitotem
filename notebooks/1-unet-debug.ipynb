{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20aa15bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv())\n",
    "from config.settings import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a984f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kristian/mambaforge/envs/mitotem/lib/python3.10/site-packages/torchvision/datapoints/__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "/home/kristian/mambaforge/envs/mitotem/lib/python3.10/site-packages/torchvision/transforms/v2/__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "/home/kristian/mambaforge/envs/mitotem/lib/python3.10/site-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 820, 820])\n",
      "[ModuleList(\n",
      "  (0): EncoderBlock(\n",
      "    (convblock): Sequential(\n",
      "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (1): ReLU()\n",
      "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (poolblock): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (1): EncoderBlock(\n",
      "    (convblock): Sequential(\n",
      "      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (1): ReLU()\n",
      "      (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (poolblock): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (2): EncoderBlock(\n",
      "    (convblock): Sequential(\n",
      "      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (1): ReLU()\n",
      "      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (poolblock): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (3): EncoderBlock(\n",
      "    (convblock): Sequential(\n",
      "      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (1): ReLU()\n",
      "      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (poolblock): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "), Sequential(\n",
      "  (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (1): ReLU()\n",
      "  (2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (3): ReLU()\n",
      "  (4): Dropout2d(p=0.5, inplace=False)\n",
      "), ModuleList(\n",
      "  (0): DecoderBlock(\n",
      "    (unpoolblock): Sequential(\n",
      "      (0): ConvTranspose2d(1024, 512, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (convblock): Sequential(\n",
      "      (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (1): ReLU()\n",
      "      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (3): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (1): DecoderBlock(\n",
      "    (unpoolblock): Sequential(\n",
      "      (0): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (convblock): Sequential(\n",
      "      (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (1): ReLU()\n",
      "      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (3): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (2): DecoderBlock(\n",
      "    (unpoolblock): Sequential(\n",
      "      (0): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (convblock): Sequential(\n",
      "      (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (1): ReLU()\n",
      "      (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (3): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (3): DecoderBlock(\n",
      "    (unpoolblock): Sequential(\n",
      "      (0): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (convblock): Sequential(\n",
      "      (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (1): ReLU()\n",
      "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (3): ReLU()\n",
      "    )\n",
      "  )\n",
      "), Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1))]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from src.models.unet import UNet\n",
    "\n",
    "unet = UNet(64)\n",
    "I = torch.randn((1,1,1004,1004))\n",
    "unet.init_weights(I)\n",
    "print(unet(I).shape)\n",
    "print(list(unet.children()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8fe43cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_next_valid_size(size: int, kernel_size: int, depth: int) -> tuple:\n",
    "    i = torch.arange(1,depth+1)\n",
    "    shrinkage = sum((kernel_size-1)*2**i).item()\n",
    "    total_shrinkage = 2*shrinkage + (kernel_size-1)*2**(depth+1)\n",
    "    while True:\n",
    "        size_after = size - shrinkage\n",
    "\n",
    "        if size_after % 2**depth == 0:\n",
    "            return size, size-total_shrinkage\n",
    "        size += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3195f43f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1004, 820)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_next_valid_size(1000,3,4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mitotem-kernel",
   "language": "python",
   "name": "mitotem-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
